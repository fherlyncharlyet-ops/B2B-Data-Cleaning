{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-5GkWjbKy0W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import requests\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    def wrong_category(data): #takes note of entries that have business models under category\n",
        "      wrong_category = []\n",
        "      business_model = ['OEM', 'End-user', 'System Integrator', 'Distributor']\n",
        "      for i in range(len(data['Category'])):\n",
        "          if data['Category'][i] in business_model:\n",
        "            wrong_category.append(1)\n",
        "          else:\n",
        "            wrong_category.append(0)\n",
        "\n",
        "      data[\"wrong_category\"] = wrong_category\n",
        "\n",
        "    def wrong_subcategory(data): #takes note of entries that have business models under subcategory\n",
        "      wrong_sub = []\n",
        "      business_model = ['OEM', 'End-user', 'System Integrator', 'Distributor']\n",
        "      for i in range(len(data['Subcategory'])):\n",
        "          if data['Subcategory'][i] in business_model:\n",
        "            wrong_sub.append(1)\n",
        "          else:\n",
        "            wrong_sub.append(0)\n",
        "\n",
        "      data['wrong_subcategory'] = wrong_sub\n",
        "\n",
        "    def wrong_business_model(data): #updates format of standard business models and takes note of wrong business models\n",
        "      business_model = ['OEM', 'End-user', 'System Integrator', 'Distributor']\n",
        "      wrong = []\n",
        "\n",
        "      for i in range(len(data)):\n",
        "        if str(data[\"Business Model\"][i]) not in business_model:\n",
        "          x = str(data[\"Business Model\"][i]).lower()\n",
        "\n",
        "          if \"services\" in x:\n",
        "            data.loc[i, 'Business Model'] = \"System Integrator\"\n",
        "\n",
        "          elif \"end\" in x:\n",
        "            data.loc[i, 'Business Model'] = \"End-user\"\n",
        "\n",
        "          elif \"oem\" in x:\n",
        "            data.loc[i, 'Business Model'] = \"OEM\"\n",
        "\n",
        "          elif \"distributor\" in x:\n",
        "            data.loc[i, 'Business Model'] = \"Distributor\"\n",
        "\n",
        "          else:\n",
        "            if \"system\" in x:\n",
        "              data.loc[i, 'Business Model'] = \"System Integrator\"\n",
        "\n",
        "      for i in range(len(data[\"Business Model\"])):\n",
        "        if str(data[\"Business Model\"][i]) not in business_model:\n",
        "          wrong.append(1)\n",
        "        else:\n",
        "          wrong.append(0)\n",
        "\n",
        "      data['wrong business model'] = wrong\n",
        "\n",
        "    def same_address_for_companies(data): #takes note of companies with the same address\n",
        "      address_counts = data.groupby('Address')['Company'].nunique().reset_index(name='Company_Count')\n",
        "\n",
        "      data['Duplicate_Address'] = data['Address'].isin(address_counts[address_counts['Company_Count'] > 1]['Address'])\n",
        "\n",
        "      mult_add = list(data[data['Duplicate_Address'] == True].index)\n",
        "\n",
        "      mult = list(np.zeros(len(data)))\n",
        "\n",
        "      for i in range(len(mult_add)):\n",
        "        mult[mult_add[i]] = 1\n",
        "\n",
        "      data.drop('Duplicate_Address', axis = 1, inplace=True)\n",
        "      data[\"address in multiple companies\"] = mult\n",
        "\n",
        "    def similar_addresses(data): #takes note of addresses under the same company that differ in format\n",
        "      data['Address'] = df['Address'].apply(lambda x: ' '.join(word.capitalize() for word in x.split()))\n",
        "      company_address = data.groupby(\"Company\")[\"Address\"].nunique()\n",
        "      company_address = company_address[company_address > 1]\n",
        "      company_names = company_address.index\n",
        "\n",
        "      space_col = list(np.zeros(len(data)))\n",
        "      char_col = list(np.zeros(len(data)))\n",
        "      letter_col = list(np.zeros(len(data)))\n",
        "      all_col = list(np.zeros(len(data)))\n",
        "\n",
        "      for y in range(len(company_names)):\n",
        "        space = []\n",
        "        extra_character = []\n",
        "        letter_case = []\n",
        "        all = []\n",
        "        index = []\n",
        "        sample = data[data['Company'] == company_names[y]]['Address'].duplicated(keep=False)\n",
        "        sample_index = list(sample.index)\n",
        "\n",
        "        for i in range(len(sample_index)):\n",
        "          if sample[sample_index[i]] == False:\n",
        "            index.append(sample_index[i])\n",
        "\n",
        "        for i in range(len(index)):\n",
        "          data_point = data[(data['Company'] == company_names[y])]['Address']\n",
        "          space.append(str(data_point[index[i]]).replace(\" \",\"\"))\n",
        "          extra_character.append(re.sub('[\\\\W\\\\d_]+', '', str(data_point[index[i]])))\n",
        "          letter_case.append(str(data_point[index[i]]).lower())\n",
        "          all.append(re.sub('[\\\\W\\\\d_]+', '', str(data_point[index[i]])).replace(\" \",\"\").lower())\n",
        "\n",
        "        space2, char,letter,all2 = [],[],[],[]\n",
        "\n",
        "        for i in range(len(index)):\n",
        "          for j in range(len(index)):\n",
        "            if i != j:\n",
        "              if space[i] == space[j]:\n",
        "                if index[i] not in space2:\n",
        "                  space2.append(index[i])\n",
        "\n",
        "                if index[j] not in space2:\n",
        "                  space2.append(index[j])\n",
        "\n",
        "              elif extra_character[i] == extra_character[j]:\n",
        "                if index[i] not in char:\n",
        "                  char.append(index[i])\n",
        "\n",
        "                if index[j] not in char:\n",
        "                  char.append(index[j])\n",
        "\n",
        "              elif letter_case[i] == letter_case[j]:\n",
        "                if index[i] not in letter:\n",
        "                  letter.append(index[i])\n",
        "\n",
        "                if index[j] not in letter:\n",
        "                  letter.append(index[j])\n",
        "\n",
        "              else:\n",
        "                if all[i] == all[j]:\n",
        "                  if index[i] not in all2:\n",
        "                    all2.append(index[i])\n",
        "\n",
        "                  if index[j] not in all2:\n",
        "                    all2.append(index[j])\n",
        "\n",
        "        for i in range(len(space2)):\n",
        "          space_col[space2[i]] = 1\n",
        "        for i in range(len(char)):\n",
        "          char_col[char[i]] = 1\n",
        "        for i in range(len(letter)):\n",
        "          letter_col[letter[i]] = 1\n",
        "        for i in range(len(all2)):\n",
        "          all_col[all2[i]] = 1\n",
        "\n",
        "      data[\"invalid address (extra space)\"] = space_col\n",
        "      data[\"invalid address (extra character)\"] = char_col\n",
        "      data[\"invalid address (letter case)\"] = letter_col\n",
        "      data[\"invalid address (extra space,character,letter case)\"] = all_col\n",
        "\n",
        "    def wrong_contact_number(data): #takes note of contact numbers that contains strings/wrong number format\n",
        "      def contains_letters(string):\n",
        "        return bool(re.search(r'[a-zA-Z]', string))\n",
        "\n",
        "      letter_no = []\n",
        "\n",
        "      data.fillna({'Contact No.': ''}, inplace = True)\n",
        "\n",
        "      for i in range(len(data)):\n",
        "        if contains_letters(str(data[\"Contact No.\"][i])) == True:\n",
        "          letter_no.append(1)\n",
        "        else:\n",
        "          letter_no.append(0)\n",
        "\n",
        "      data[\"invalid contact no.\"] = letter_no\n",
        "\n",
        "    def wrong_fax_number(data): #takes note of fax numbers that contains strings/wrong number format\n",
        "      def contains_letters(string):\n",
        "        return bool(re.search(r'[a-zA-Z]', string))\n",
        "\n",
        "      letter =[]\n",
        "\n",
        "      data.fillna({'Fax No.': ''}, inplace = True)\n",
        "\n",
        "      for i in range(len(data)):\n",
        "        if contains_letters(str(data[\"Fax No.\"][i])) == True:\n",
        "          letter.append(1)\n",
        "        else:\n",
        "          letter.append(0)\n",
        "\n",
        "      data[\"invalid fax no.\"] = letter\n",
        "\n",
        "    def contains_only_digits(string):\n",
        "        if isinstance(string, str):\n",
        "            return bool(re.match(r'^\\d+$', string))\n",
        "        return False\n",
        "\n",
        "    def find_and_write_invalid_employees_indices(data): #takes note of entries with invalid employee numbers\n",
        "\n",
        "        data['Employees'] = data['Employees'].astype(str).str.replace(',', '').str.split('.', expand=True)[0]\n",
        "        non_numeric_indices = [index for index, value in data['Employees'].items() if not contains_only_digits(value)]\n",
        "        data['invalid_employees'] = 0\n",
        "        data.loc[non_numeric_indices, 'invalid_employees'] = 1\n",
        "        numeric_indices = data['Employees'].str.isdigit()\n",
        "        data.loc[numeric_indices & (data['invalid_employees'] == 0), 'invalid_employees'] = 0\n",
        "\n",
        "    def get_sales_outliers(data): #takes note of sales outliers\n",
        "        data_copy = data.copy()\n",
        "        data_copy['Annual Sales'] = pd.to_numeric(data_copy['Annual Sales'].astype(str).str.replace(',', ''), errors='coerce')\n",
        "\n",
        "        pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "        Q1 = data_copy['Annual Sales'].quantile(0.25)\n",
        "        Q3 = data_copy['Annual Sales'].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        outlier_indices = data_copy.index[(data_copy['Annual Sales'] < lower_bound) | (data_copy['Annual Sales'] > upper_bound)]\n",
        "        data['outlier_annual_sale'] = 0\n",
        "        data.loc[outlier_indices, 'outlier_annual_sale'] = 1\n",
        "\n",
        "        non_numeric_indices = data_copy[data_copy['Annual Sales'].isna()].index\n",
        "        data.loc[non_numeric_indices, 'outlier_annual_sale'] = 1\n",
        "        data.loc[non_numeric_indices, 'Annual Sales'] = np.nan\n",
        "\n",
        "    def detect_outliers_by_state(data): #takes note of state outliers\n",
        "        data['State'] = data['State'].apply(lambda state: state.strip(\" ./,\") if isinstance(state, str) else state)\n",
        "        data['State'] = data['State'].apply(lambda state: state.capitalize() if isinstance(state, str) else state)\n",
        "        data['Latitude'] = pd.to_numeric(data['Latitude'], errors='coerce')\n",
        "        data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')\n",
        "\n",
        "        grouped = data.groupby('State')\n",
        "        data['State'] = data['State'].str.strip().str.lower()\n",
        "\n",
        "        def detect_outliers(values):\n",
        "            Q1 = np.percentile(values, 25)\n",
        "            Q3 = np.percentile(values, 75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            return (values < lower_bound) | (values > upper_bound)\n",
        "\n",
        "        state_outliers = {}\n",
        "\n",
        "        outlier_indices = []\n",
        "\n",
        "        for state, group in grouped:\n",
        "            group['outlier_latitude'] = detect_outliers(group['Latitude']).astype(int)\n",
        "            group['outlier_longitude'] = detect_outliers(group['Longitude']).astype(int)\n",
        "\n",
        "            group['outlier_latitude'] = (group['outlier_latitude'] == 1).astype(int)\n",
        "            group['outlier_longitude'] = (group['outlier_longitude'] == 1).astype(int)\n",
        "\n",
        "            state_outliers[state] = {'outlier_latitude': group['outlier_latitude'].tolist(),\n",
        "                                     'outlier_longitude': group['outlier_longitude'].tolist()}\n",
        "\n",
        "            data.loc[group.index, ['outlier_latitude', 'outlier_longitude']] = group[['outlier_latitude', 'outlier_longitude']].values\n",
        "\n",
        "            outlier_indices.extend(group[group['outlier_latitude'] == 1].index)\n",
        "            outlier_indices.extend(group[group['outlier_longitude'] == 1].index)\n",
        "\n",
        "        data[['outlier_latitude', 'outlier_longitude']] = data[['outlier_latitude', 'outlier_longitude']].fillna(1)\n",
        "        non_numeric_indices_long = data[data['Longitude'].isna()].index\n",
        "        non_numeric_indices_lat = data[data['Latitude'].isna()].index\n",
        "        data.loc[non_numeric_indices_long, 'outlier_longitude'] = 1\n",
        "        data.loc[non_numeric_indices_lat, 'outlier_latitude'] = 1\n",
        "        data['State'] = data['State'].str.title()\n",
        "\n",
        "        return data, state_outliers\n",
        "\n",
        "    def clean_email_and_website(data): #interchanges wrong entries under website and email\n",
        "        data.fillna({'Email': ''}, inplace = True)\n",
        "        data.fillna({'Website': ''}, inplace = True)\n",
        "\n",
        "        email_pattern = re.compile(r'\\b([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,})\\b')\n",
        "        website_pattern = re.compile(r'\\b(?:https?://)?(?:www\\.)?([^\\s]+)\\b')\n",
        "\n",
        "        emails = data['Email'].str.extract(email_pattern, expand=False)\n",
        "        websites = data['Website'].str.extract(website_pattern, expand=False)\n",
        "\n",
        "        email_contains_website_mask = emails.str.contains(r'www\\.', na=False)\n",
        "        website_contains_email_mask = websites.str.contains(r'@', na=False)\n",
        "\n",
        "        data.loc[email_contains_website_mask, ['Email', 'Website']] = data.loc[email_contains_website_mask, ['Website', 'Email']].values\n",
        "        data.loc[website_contains_email_mask, ['Email', 'Website']] = data.loc[website_contains_email_mask, ['Website', 'Email']].values\n",
        "\n",
        "        empty_website_mask = (data['Website'] == '') & data['Email'].str.contains(r'http[s]?://|www\\.', na=False)\n",
        "        data.loc[empty_website_mask, ['Email', 'Website']] = data.loc[empty_website_mask, ['Website', 'Email']].values\n",
        "\n",
        "        return data\n",
        "\n",
        "    def check_state_in_address(data):\n",
        "        # Function to handle NaN and non-string values\n",
        "        def clean_string(value):\n",
        "            if isinstance(value, str):\n",
        "                return value.lower()\n",
        "            else:\n",
        "                return str(value).lower()  # Convert non-string to string and then to lowercase\n",
        "\n",
        "        # Apply cleaning function to State and Address columns\n",
        "        data['State'] = data['State'].apply(clean_string)\n",
        "        data['Address'] = data['Address'].apply(clean_string)\n",
        "\n",
        "        # Create new column state_not_in_address based on the comparison\n",
        "        data['state_not_in_address'] = data.apply(lambda row: 0 if row['State'] in row['Address'] else 1, axis=1)\n",
        "\n",
        "        return data\n",
        "\n",
        "    def invalid_state(state, valid_states):\n",
        "        if isinstance(state, str):  # Check if state is already a string\n",
        "            state = state.strip()   # Strip leading/trailing whitespace if it's a string\n",
        "            state = ''.join(state.split())\n",
        "        if state not in valid_states:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    file_name = str(input('Enter File Name (include .csv): '))\n",
        "    valid_states = input('Enter Valid State List (comma-separated): ').split(',')\n",
        "    valid_states = [' '.join(word.capitalize() for word in state.split()) for state in valid_states]\n",
        "    valid_states = [valid_state.replace(' ', '') for valid_state in valid_states]\n",
        "    df = pd.read_csv(file_name)\n",
        "    df = df.drop_duplicates(ignore_index = True) #drops duplicate entries\n",
        "    df['invalid_state'] = df['State'].apply(lambda x: invalid_state(x, valid_states))\n",
        "    check_state_in_address(df)\n",
        "    wrong_business_model(df)\n",
        "    wrong_category(df)\n",
        "    wrong_subcategory(df)\n",
        "    same_address_for_companies(df)\n",
        "    wrong_contact_number(df)\n",
        "    wrong_fax_number(df)\n",
        "    similar_addresses(df)\n",
        "    contains_only_digits(df['Employees'])\n",
        "    find_and_write_invalid_employees_indices(df)\n",
        "    get_sales_outliers(df)\n",
        "    detect_outliers_by_state(df)\n",
        "    clean_email_and_website(df)\n",
        "\n",
        "    # with open('API-Key.txt', 'r') as file: #reads the API key\n",
        "    #   GOOGLE_MAPS_API_KEY = str(file.read())\n",
        "\n",
        "    # async def get_lat_and_lng(address): #collect the coordinates from google maps\n",
        "    #     try :\n",
        "    #         url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={GOOGLE_MAPS_API_KEY}\"\n",
        "    #         response = await asyncio.get_event_loop().run_in_executor(\n",
        "    #             None, lambda: requests.get(url)\n",
        "    #         )\n",
        "    #         data = response.json()\n",
        "    #         lat = data[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
        "    #         lng = data[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
        "\n",
        "    #         return {\"latitude\": lat, \"longitude\": lng}\n",
        "    #     except Exception as e:\n",
        "    #         print(\"################### [ Error in getting coordinates ] ######################\")\n",
        "    #         print(f\"Error : {e}\")\n",
        "    #         return {\"latitude\": None, \"longitude\": None}\n",
        "\n",
        "    # async def main():\n",
        "\n",
        "    #   addresses = df[\"Address\"]\n",
        "    #   coordinates = []\n",
        "\n",
        "    #   for i in range(len(addresses)):\n",
        "    #       if df['outlier_latitude'][i] == 1 or df['outlier_longitude'][i] == 1: #gets coordinates of entries with no coordinates or marked as an outlier\n",
        "    #         print(f\"Getting coordinates for address {i + 1}\")\n",
        "    #         print(addresses[i])\n",
        "\n",
        "    #         address = addresses[i]\n",
        "    #         coordinates.append(\n",
        "    #             {\"address\": address, \"coordinates\": await get_lat_and_lng(address)}\n",
        "    #         )\n",
        "\n",
        "    #         print(f\"Latitude: {coordinates[-1]['coordinates']['latitude']}\")\n",
        "    #         print(f\"Longitude: {coordinates[-1]['coordinates']['longitude']}\\n\")\n",
        "\n",
        "    #         df.loc[i, 'Latitude'] = coordinates[-1]['coordinates']['latitude']\n",
        "    #         df.loc[i, 'Longitude'] = coordinates[-1]['coordinates']['longitude']\n",
        "\n",
        "    # asyncio.run(main())\n",
        "\n",
        "    detect_outliers_by_state(df) # updates the entries marked as missing coordinates but already have coordinates\n",
        "\n",
        "\n",
        "    save_name = str(input('Enter Save Name (include .csv): '))\n",
        "    df.to_csv(save_name, index = False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "CzRmukLwLDEt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}